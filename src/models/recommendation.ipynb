{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow tensorflow-recommenders\n",
    "# \n",
    "from typing import Dict, Text, Union\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import pandas as pd\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import importlib\n",
    "\n",
    "USE_MOD_URL = 'https://tfhub.dev/google/universal-sentence-encoder/4'\n",
    "EVENTS_PATH = \"/home/thusitha/work/projects/recommendation_take_home/data/sample_1k_users.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3143221, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>behavior_type</th>\n",
       "      <th>user_location_hash</th>\n",
       "      <th>item_category</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90795949</td>\n",
       "      <td>402391768</td>\n",
       "      <td>1</td>\n",
       "      <td>94h6dlp</td>\n",
       "      <td>3046</td>\n",
       "      <td>2014-12-09 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90795949</td>\n",
       "      <td>116725988</td>\n",
       "      <td>1</td>\n",
       "      <td>94h6dkp</td>\n",
       "      <td>3487</td>\n",
       "      <td>2014-12-17 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90795949</td>\n",
       "      <td>230564881</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11489</td>\n",
       "      <td>2014-11-28 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90795949</td>\n",
       "      <td>327767037</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12855</td>\n",
       "      <td>2014-12-09 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90795949</td>\n",
       "      <td>79851069</td>\n",
       "      <td>1</td>\n",
       "      <td>94h6dkc</td>\n",
       "      <td>5037</td>\n",
       "      <td>2014-12-10 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143216</th>\n",
       "      <td>84420232</td>\n",
       "      <td>58229968</td>\n",
       "      <td>1</td>\n",
       "      <td>95qqs15</td>\n",
       "      <td>8141</td>\n",
       "      <td>2014-12-12 07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143217</th>\n",
       "      <td>84420232</td>\n",
       "      <td>357613414</td>\n",
       "      <td>2</td>\n",
       "      <td>95qqs1o</td>\n",
       "      <td>6513</td>\n",
       "      <td>2014-12-06 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143218</th>\n",
       "      <td>84420232</td>\n",
       "      <td>194792004</td>\n",
       "      <td>1</td>\n",
       "      <td>95qqsut</td>\n",
       "      <td>8141</td>\n",
       "      <td>2014-12-12 07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143219</th>\n",
       "      <td>84420232</td>\n",
       "      <td>60277228</td>\n",
       "      <td>1</td>\n",
       "      <td>95qqs1a</td>\n",
       "      <td>8141</td>\n",
       "      <td>2014-12-12 07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143220</th>\n",
       "      <td>84420232</td>\n",
       "      <td>49477445</td>\n",
       "      <td>1</td>\n",
       "      <td>95qqs01</td>\n",
       "      <td>8141</td>\n",
       "      <td>2014-12-12 07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3143221 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id    item_id  behavior_type user_location_hash  item_category  \\\n",
       "0        90795949  402391768              1            94h6dlp           3046   \n",
       "1        90795949  116725988              1            94h6dkp           3487   \n",
       "2        90795949  230564881              1                NaN          11489   \n",
       "3        90795949  327767037              3                NaN          12855   \n",
       "4        90795949   79851069              1            94h6dkc           5037   \n",
       "...           ...        ...            ...                ...            ...   \n",
       "3143216  84420232   58229968              1            95qqs15           8141   \n",
       "3143217  84420232  357613414              2            95qqs1o           6513   \n",
       "3143218  84420232  194792004              1            95qqsut           8141   \n",
       "3143219  84420232   60277228              1            95qqs1a           8141   \n",
       "3143220  84420232   49477445              1            95qqs01           8141   \n",
       "\n",
       "                  time  \n",
       "0        2014-12-09 21  \n",
       "1        2014-12-17 23  \n",
       "2        2014-11-28 00  \n",
       "3        2014-12-09 23  \n",
       "4        2014-12-10 12  \n",
       "...                ...  \n",
       "3143216  2014-12-12 07  \n",
       "3143217  2014-12-06 12  \n",
       "3143218  2014-12-12 07  \n",
       "3143219  2014-12-12 07  \n",
       "3143220  2014-12-12 07  \n",
       "\n",
       "[3143221 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_dt = pd.read_csv(EVENTS_PATH)\n",
    "print(events_dt.shape)\n",
    "events_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3143221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 08:28:51.289457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 08:28:51.294195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 08:28:51.294573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 08:28:51.295311: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-02 08:28:51.295797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 08:28:51.296148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 08:28:51.296529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 08:28:51.599499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 08:28:51.599902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 08:28:51.600216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-02 08:28:51.600517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6831 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:09:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "#events_ts_ds = tf.data.Dataset.from_tensor_slices(dict(events_dt[[\"resume_id\", \"job_id\"]]))\n",
    "events_ts_ds = tf.data.Dataset.from_tensor_slices(dict(events_dt[[\"user_id\", \"item_id\"]]))\n",
    "print(len(events_ts_ds))\n",
    "\n",
    "events_ds = events_ts_ds.map(lambda x: {\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"item_id\": x[\"item_id\"]\n",
    "})\n",
    "\n",
    "items_ds = events_ts_ds.map(lambda x: {\n",
    "    \"item_id\": x[\"item_id\"]\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_ids_vocabulary = tf.keras.layers.IntegerLookup(mask_token=None)\n",
    "unique_user_ids = np.unique(events_dt[\"user_id\"])\n",
    "user_ids_vocabulary.adapt(unique_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "item_ids_vocabulary = tf.keras.layers.IntegerLookup(mask_token=None)\n",
    "unique_item_ids = np.unique(events_dt[\"item_id\"])\n",
    "item_ids_vocabulary.adapt(unique_item_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906 832916\n"
     ]
    }
   ],
   "source": [
    "print(user_ids_vocabulary.vocabulary_size(), item_ids_vocabulary.vocabulary_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2828898 314323\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled_data = events_ds.shuffle(len(events_ds))\n",
    "\n",
    "n_train = int(len(events_ds)*0.9)\n",
    "n_test = len(events_ds) - n_train\n",
    "\n",
    "#n_train = int(len(events_ds)*0.10)\n",
    "#n_test = int(len(events_ds)*0.10)\n",
    "\n",
    "train = shuffled_data.take(n_train)\n",
    "test = shuffled_data.skip(n_train).take(n_test)\n",
    "\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import models.recomender_model\n",
    "importlib.reload(models.recomender_model)\n",
    "from models.recomender_model import DEFAULTS, RecommenderModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'item_id': <tf.Tensor 'args_0:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = None\n",
    "gc.collect()\n",
    "model = RecommenderModel(user_ids_vocabulary, item_ids_vocabulary, items_ds, dense_layers = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cached_train = train.batch(DEFAULTS[\"batch_size\"]).cache()\n",
    "cached_test = test.batch(DEFAULTS[\"batch_size\"]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'item_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'item_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'item_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'item_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "691/691 [==============================] - 22s 27ms/step - top_10_categorical_accuracy: 0.0000e+00 - top_100_categorical_accuracy: 0.0000e+00 - loss: 33748.3864 - regularization_loss: 0.0000e+00 - total_loss: 33748.3864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe828ea8ca0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "model.fit(cached_train, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'item_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'user_id': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=int64>, 'item_id': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "30/39 [======================>.......] - ETA: 3:08 - top_10_categorical_accuracy: 0.0031 - top_100_categorical_accuracy: 0.0288 - loss: 32590.1562 - regularization_loss: 0.0000e+00 - total_loss: 32590.1562"
     ]
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Create a retrieval model.\n",
    "\n",
    "# # Use brute-force search to set up retrieval using the trained representations.\n",
    "# index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# index.index_from_dataset(\n",
    "#     test.batch(100).map(lambda x:x[\"job_id\"]).map(lambda _id: (_id, model.jobs_model(_id))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Get some recommendations.\n",
    "# _, titles = index(np.array([2]))\n",
    "# print(f\"Top 3 recommendations for user 1: {titles[0, :3]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow_hub as hub\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_text\n",
    "\n",
    "# USE_MOD_URL = 'https://tfhub.dev/google/universal-sentence-encoder/4'\n",
    "\n",
    "# embed = hub.load(URL)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afa0836637ead3be21eb3bea5327d759b706375c4188b83f7d28112a3bd99171"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('seek-analysis': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}